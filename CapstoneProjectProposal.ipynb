{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Proposal\n",
    "### Udacity ML Engineering Nanodegree \n",
    "Kenneth Preston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this capstone project proposal I will outline the following project details:\n",
    "\n",
    "- The project's domain background — the field of research where the project is derived;\n",
    "- A problem statement — a problem being investigated for which a solution will be defined;\n",
    "-  datasets and inputs — data or inputs being used for the problem;\n",
    "- A solution statement — the solution proposed for the problem given;\n",
    "- A benchmark model — some simple or historical model or result to compare the defined solution to;\n",
    "- A set of evaluation metrics — functional representations for how the solution can be measured;\n",
    "- An outline of the project design — how the solution will be developed and results obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) The project's domain background\n",
    "...The field of research where the project is derived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is derived from the marketing field. The technique I am using is OCR (i.e. computer vision and object detection) to read images of instore product sales tags and other promotional material. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) A problem statement \n",
    "...a problem being investigated for which a solution will be defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A company currently has thousands of instore images of product tags and promotional material. This project would be similar to this one I found online (https://super-geek-news.github.io/articles/415657/index.html & https://medium.com/capital-one-tech/learning-to-read-computer-vision-methods-for-extracting-text-from-images-2ffcdae11594 ). This data is currently underutilzied as it requires a human to review all the images. There is no process currently for transcribing these images into text. This project is looking to use a machine learning application to process these images and extract the text with a high level of accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Datasets and inputs \n",
    "...data or inputs being used for the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to use a training set that does not include any private data to avoid any legal or ethical complications. To complete this project and be able to release it publically, I will be using a public dataset. This dataset is DeTEXT: A Database for Extracting TEXT from biomedical literature figures. It is available here for download: http://prir.ustb.edu.cn/DeTEXT/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) A solution statement \n",
    "...the solution proposed for the problem given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using sagemaker's training resources I will design a custom deep learning ocr model to locate text in an image and return the text. This model will then be connected with an API and a website will be built where a image can be uploaded and the text results will be returned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) A benchmark model\n",
    "...some simple or historical model or result to compare the defined solution to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have previously attempted to use tesseract ocr alone to address this problem. The results were inaccurate and unreliable. I can compare to the tesseract model to this approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) A set of evaluation metrics\n",
    "...functional representations for how the solution can be measured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I plan to evaluate based on character level accuracy as described here: https://abbyy.technology/en:kb:tip:ocr-accuracy\n",
    "    \n",
    "\n",
    "\n",
    "### \"\"\"\"Below is an extract from https://abbyy.technology/en:kb:tip:ocr-accuracy \"\"\"\"\n",
    "### Measurement of OCR Accuracy\n",
    "Accuracy on a Character Level\n",
    "OCR technology provider normally measure the accuracy of the optical character recognition results on a character level.\n",
    "Examples\n",
    "- 99% accuracy means that 1 out of 100 characters\n",
    "or 10 out of 1000 characters are recognized “uncertain”\n",
    "- 99,9% accuracy means that\n",
    "1 out of 1000 characters are recognized “uncertain”\n",
    "\n",
    "### \"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"END\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) An outline of the project design\n",
    "...how the solution will be developed and results obtained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Development: \n",
    "\n",
    "Although I could use the prepackaged textract api from amazon, I will instead build a custom approach. The approach I am going to use an object detection algorithm to detect text in images. I will consider either of these approaches outlined below:\n",
    "\n",
    "- https://github.com/awslabs/amazon-sagemaker-examples/blob/master/introduction_to_amazon_algorithms/object_detection_pascalvoc_coco/object_detection_incremental_training.ipynb\n",
    "- https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/distributed_tensorflow_mask_rcnn/mask-rcnn-s3.ipynb\n",
    "\n",
    "Then I will use an approach to convert the located text on the images into actual characters. \n",
    "\n",
    "I will try some of these approaches to accomplish this:\n",
    "- BeamSearch: https://github.com/githubharald/CTCWordBeamSearch\n",
    "- Tesseract: https://pypi.org/project/pytesseract/\n",
    "\n",
    "#### Deployment:\n",
    "\n",
    "Deployment will be carried out in the following way:\n",
    "    - Tested model will be deployed to an endpoint. \n",
    "    - API will be set up to connect with a website. \n",
    "    - Lambda function will be used to processs the image before going to the model\n",
    "    - Website ui will be designed to upload file from website to the api\n",
    "    \n",
    "#### User results:\n",
    "\n",
    "The processed image with extracted text will be returned to the user through the website.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
